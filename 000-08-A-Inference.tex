Here's your content tidied up, structured for clarity, and organized into clean Markdown with section headings and no duplication:

---

# What Is Statistical Inference?

Statistical inference is the process of drawing conclusions about a population based on data obtained from a sample.

- It involves estimating unknown parameters that define a theoretical model assumed to have generated the data.
- The model itself is not directly observable; rather, we infer information about it using sample statistics.

---

# Types of Inference Procedures

There are two main types:

1. **Confidence Intervals**  
   - Provide a range of plausible values for a population parameter.
   - Associated with a confidence level (e.g., 95%).

2. **Hypothesis Tests**  
   - Test the plausibility of a specific claim about a population parameter.
   - Can be conducted in two ways:
     - Compare test statistic to critical values.
     - Compare p-value to the significance level (the method emphasized in this course).

---

## The p-Value

- The p-value is the probability of observing a test statistic as extreme or more extreme than what was actually observed, assuming the null hypothesis is true.
- It quantifies the strength of evidence against the null hypothesis.

---

# Assumptions for Testing Claims About Population Means

To conduct valid tests about population means, the following assumptions are generally required:

- The sample must be a simple random sample.
- The population variance \( \sigma \) is known.
- Additionally, at least one of these must hold:
  - The population is normally distributed.
  - The sample size \( n > 30 \) (large sample approximation).

---

# Point Estimates

Statisticians use sample statistics as point estimates of population parameters.

### Common Examples:
- Sample mean \( \bar{x} \) → estimate of population mean \( \mu \)
- Sample proportion \( \hat{p} \) → estimate of population proportion \( \pi \)

## Definition

A **point estimate** is a single-number summary from a sample that serves as the best guess for a corresponding population parameter.

- The sample mean \( \bar{x} \) is an **unbiased estimate** of the true population mean \( \mu \).
- However, some error is always associated with a point estimate, as it might not equal the true value.

---

# Interval Estimation

To account for uncertainty, statisticians often use interval estimates called **confidence intervals**.

- A confidence interval specifies a range of plausible values for a population parameter.
- It also controls the probability (confidence level) that the true value lies within this range.

---


Here’s your content restructured and formatted as clean, consistent Markdown with clear section headings and without duplication:

---

# Confidence Intervals

- Degrees of freedom (\( \nu \)) depend on sample size:
  - **Large samples** (\( n > 30 \)): \( \nu = \infty \)
  - **Small samples** (\( n \leq 30 \)): \( \nu = n - 1 \)

---

# Hypothesis Testing and p-values

- In hypothesis testing, we calculate the difference between the observed statistic and the parameter value under \( H_0 \), then determine the probability of obtaining such a difference (or more extreme) if \( H_0 \) is true.
- This probability is called the **p-value**.
- **Important Clarification**: A p-value (e.g., 0.0175) does **not** represent the probability that the null hypothesis is true. Rather, it is the probability of seeing data as extreme or more extreme than what was observed, assuming \( H_0 \) is true.

### Significance Illustration (Die Throw Example)

- Suppose a die throw experiment yields a sum of 401.
- Simulations show that only about 1.75% of throws from a fair die produce this result.
- If the die were crooked (favoring high values), the result wouldn't be surprising.
- The experiment **suggests** bias but doesn’t **prove** it.
- Errors in judgment (Type I and Type II) will be discussed later.

---

# Inference

## Standard Errors

For testing population proportions:

### Hypotheses

\[
H_0: p = p_0 \\
H_a: p \neq p_0
\]

### Standard Error Formula

\[
SE(\hat{p}) = \sqrt{ \frac{p_0(1 - p_0)}{n} }
\]

---

# Test Design Considerations

- **Significance level**: \( \alpha \)
- **Confidence level**: \( 1 - \alpha \)

### Tailed Procedures

- **One-tailed test**: hypothesis suggests direction (e.g., greater than)
- **Two-tailed test**: hypothesis tests for any difference

> Note: Confidence intervals are always based on two-tailed procedures.

### Sample Size

- Influences degrees of freedom, which affect the t-distribution:
  - \( df = n - 1 \)

---

## Two-Tailed Hypothesis Test Example

- Null: \( H_0: \mu = \mu_0 \)
- Alternative: \( H_1: \mu \neq \mu_0 \)
- The significance level \( \alpha \) is split equally between both tails.
- "Not equal to" implies either "less than" or "greater than."

---

# Assumptions: Tests with Unknown Variance

To test claims about population means when variance \( \sigma \) is unknown:

### Required Conditions

- The sample must be a **simple random sample**
- At least one of:
  - Population is **normally distributed**
  - Sample size \( n > 30 \)

---

## t-Test Formula

\[
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}}
\]

- Degrees of freedom: \( df = n - 1 \)

---

Here’s your text polished and organized in clear, structured Markdown with tidy formatting, labeled sections, and corrected duplication or incomplete statements:

---

# Standard Error of a Proportion

### General Formula
\[
\mbox{S.E.}(\hat{p}) = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
\]

### For Hypothesis Testing
\[
\mbox{S.E.}(\hat{p}) = \sqrt{\frac{p_0(1 - p_0)}{n}}
\]
- Where \( p_0 \) is the population proportion assumed under the null hypothesis.

---

# Confidence Intervals

## Margin of Error
\[
E = \frac{\text{Upper conf. limit} - \text{Lower conf. limit}}{2}
\]

## Point Estimates
- The sample proportion \( \hat{p} \) is the best point estimate of the population proportion \( p \).

## Pooled Estimate (for two proportions)
\[
\bar{p} = \frac{x_1 + x_2}{n_1 + n_2}
\]
- Represents the overall proportion of successes in the combined sample.

## Inferences for Matched Pairs — Assumptions
1. Data consists of matched pairs.  
2. Samples are simple random samples.

## Standard Error of a Sample Mean
\[
\mbox{S.E.}(\bar{x}) = \frac{\sigma}{\sqrt{n}}
\]

## Confidence Interval for a Mean (Small Sample)
\[
\bar{x} \pm t_{1-\alpha/2,\,n-1} \times \frac{s}{\sqrt{n}}
\]
- Where \( t_{1-\alpha/2,\,n-1} \) is the critical value from the Student’s t-distribution with \( n - 1 \) degrees of freedom.

---

# Two-Sample t-Test Example

**Problem:**  
Compare education levels between two independent samples:

| Group       | Sample Size | Mean Years | Std. Dev. |
|-------------|-------------|------------|-----------|
| City A      | 38          | 15         | 2         |
| City B      | 30          | 14         | 2.5       |

**Question:** Is the difference in mean education statistically significant?

---

# Type I and Type II Errors — Die Example

- Two dice are tested, resulting in sums of 401 and 360.
- We don't know whether either die is fair or biased.
- A result like 401 is rare under fairness (only ~1.75% chance), but may be common for a biased die.
- This illustrates uncertainty and the possibility of decision errors:
  - **Type I Error:** Incorrectly rejecting a true null hypothesis.
  - **Type II Error:** Failing to reject a false null hypothesis.

---

# Hypothesis Testing Summary

### Common Methods
- Paired t-test
- Difference of two means (large samples)
- Difference of two means (small samples)
- Difference of two proportions (large samples only)

### Example Setup

- Test statistic (TS) = 2.7  
- Significance level \( \alpha = 0.05 \)  
- All examples use a two-tailed test  
- Critical value (CV) = 1.96 for large samples  
- For small samples, CV depends on \( t_{n-1} \)

**Note:** All examples will use the same TS and \( \alpha \) to show consistency across methods.

---

# Computing Standard Error and Test Statistic

- **Point Estimate:** \( \bar{x}_1 - \bar{x}_2 \)
- **Standard Error:** Calculated using appropriate formulae
- **Test Statistic:**  
  \[
  TS = \frac{(\bar{x}_1 - \bar{x}_2) - 0}{\mbox{S.E.}(\bar{x}_1 - \bar{x}_2)}
  \]

---


\textbf{Difference of proportions}

\begin{itemize}
\item The point estimate is the difference 
\item Observed difference  = $7\%$. Under the null hypothesis, the expected difference is $0\%$
\item The standard error formulae
\end{itemize}





%================================================================================%
Example 1
A fair die is thrown. The number shown on the die is the random variable X. Tabulate the possible outcomes.
Solution
X takes the six possible outcomes 1, 2, 3, 4, 5, 6 which each have probability 1/6 (i.e. one sixth).

r 1 2 3 4 5 6
P(X = r)1/6 1/6 1/6 1/6 1/6 1/6
Example 2
Two unbiased spinners, one numbered 1, 3, 5, 7 and the other numbered 1, 2, 3 are spun. The random variable X is the sum of the two results.
Find the probability distribution for X.



Solution
Listing all the possible outcomes is best done in a table.




%================================================================================%



\subsection{Question 3.2 }


What is the probability of getting a number divisible by 3 in each of 3 throws of a dice?




Solution



Numbers divisible by 3 : 3 and 6            probability of throwing 3 or 6:   



Probability of throwing 3 or 6 three times in a row  ( Each throw of a dice is an independent event.)



P[3T] = P[T]P[T]P[T]=133=127

%================================================================================%



Here’s a tidied and structured version of your notes, organized into clean Markdown with section headings for clarity:

---

# Revision for Inference Procedures

## Key Concepts

- Definitions and terminology
- Computing confidence intervals
- Performing hypothesis testing:
  - Comparing test statistics to critical values
  - Using p-value interpretation
  - Applying the confidence interval method

---

# Question Summaries

### Question 3

- Formula in decimal form:  
  \[
  \sqrt{ \hat{p}(1 - \hat{p}) }
  \]
- For easier pen-and-paper calculations using percentages:
  \[
  \sqrt{ \hat{p}(100 - \hat{p}) }
  \]

### Question 4

- Will be revisited in next week’s tutorial.
- No need to complete it now.

### Question 7

- **Point Estimate**: Sample mean \( \bar{X} \)
- **Quantile for 95% CI**: 1.96
- Justification for using 1.96 not required if sample is large.

### Question 8

- **Point Estimate**: \( \hat{p} = \frac{x}{n} = 68.8\% \)
- Useful percentage-based formula:
  \[
  \sqrt{ \hat{p}(100 - \hat{p}) }
  \]

---

# Confidence Intervals

## General Structure

\[
\text{Observed Value} \pm (\text{Quantile} \times \text{Standard Error})
\]

## Margin of Error

\[
E = \frac{\text{Upper Confidence Limit} - \text{Lower Confidence Limit}}{2}
\]

## Examples

### Example 1

- Population of men:  
  - Normally distributed weights  
  - Mean: 172 lbs  
  - Std. Dev.: 29 lbs

### Example 2

- Let \( X \) be the score from throwing a die.  
- Regardless of the underlying distribution, statistics tend to follow a normal distribution (Central Limit Theorem).

---

# Standard Error and the Central Limit Theorem

## Standard Error

- As sample size increases, the sampling distribution approximates normality.

## Central Limit Theorem

- Applies to sample of size \( n \)
- Population variance \( \sigma^2 \) unknown → estimate with sample variance \( s^2 \)

---

# New Section: Exam Formulae

- A schedule of formulae will be provided at the back of your exam paper.
- This schedule will be posted on SULIS.
- It’s advised to review this content before the exam.
- Reach out if you encounter any issues.

---







Here’s a refined and well-structured Markdown version of your revision material for inference procedures and confidence intervals:

---

# Confidence Intervals: Revision

- A **95% confidence interval** is a range of values expected to contain the true population parameter (e.g. mean, proportion) with 95% probability.
- This implies the interval may **miss** the true value 5% of the time.
- Confidence levels can vary; common choices include:
  - 90% (\( \alpha = 0.10 \))
  - 95% (\( \alpha = 0.05 \))
  - 99% (\( \alpha = 0.01 \))
  - 99.9% (\( \alpha = 0.001 \))

---

## Confidence Level Explained

- The confidence level is denoted as \( 1 - \alpha \), where \( \alpha \) is the significance level.
- For example:
  \[
  100(1 - \alpha)\% = 100(1 - 0.05)\% = 95\%
  \]
- Higher confidence levels imply more conservative intervals.
- The value of \( \alpha \) is critical in determining the appropriate quantile from distributions.

---

## Accuracy of Point Estimates

- The sample mean \( \bar{x} \) is an **unbiased estimator** of the population mean \( \mu \), but not perfectly accurate.
- Mathematically, the probability that \( \bar{x} \) equals \( \mu \) exactly is zero: \( P = 0 \).
- Confidence intervals are necessary to capture the range where \( \mu \) likely lies.

---

## Applicability of the Normal Distribution

- Use the normal distribution if:
  - The sample size \( n > 30 \)
  - OR the population is normally distributed **and** \( \sigma \) is known for small samples

- If \( \sigma \) is **unknown** in small samples, use the **Student's t-distribution** with:
  \[
  df = n - 1
  \]

---

## Computing the Standard Error for a Proportion

### When Using Percentages:

\[
SE(\hat{p}) = \sqrt{ \frac{ \hat{p}(100 - \hat{p}) }{n} }
\]

Example:
- Successes: \( x = 144 \)
- Sample size: \( n = 200 \)
- Proportion:  
  \[
  \hat{p} = \frac{144}{200} \times 100\% = 72\%
  \]
- Complement: \( 100\% - 72\% = 28\% \)
- Standard Error:
  \[
  SE(\hat{p}) = \sqrt{ \frac{72 \times 28}{200} }
  \]

### When Using Decimals (for Hypothesis Testing):

\[
SE(\hat{p}) = \sqrt{ \frac{p_0(1 - p_0)}{n} }
\]

Where \( p_0 \) is the population proportion under the null hypothesis.

---

## Computing the Point Estimate

\[
\hat{p} = \frac{x}{n} \times 100\%
\]

Where:
- \( x \): number of successes  
- \( n \): sample size  
- \( \hat{p} \): sample proportion

---

# Inference for Proportions

### Hypotheses

\[
H_0: p = p_0 \\
H_a: p \neq p_0
\]

### Formula for Standard Error

\[
SE(\hat{p}) = \sqrt{ \frac{p_0(1 - p_0)}{n} }
\]

---

## Key Exam Resources and Considerations

### Formula Tables

- Murdoch Barnes Table 3: Z distribution
- Murdoch Barnes Table 7: Student’s t distribution

### Considerations

- **Significance level \( \alpha \)** and **confidence level \( 1 - \alpha \)**
- **Number of tails**:
  - One-tailed or two-tailed tests
  - Confidence intervals are always two-tailed
- **Sample size** impacts the degrees of freedom in small sample tests

---
